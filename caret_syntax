################################################
#Models:
#Compiled by:Linlin Cheng
################################################
################################################
library(caret) 
(confusionMatrix())
library(pROC)
(roc())
################################################
#1.General Caret Models: Two class classification:

MyTrainControl=trainControl(
  method = "repeatedCV",
  number=10,
  repeats=5,
  returnResamp = "all",
  classProbs = TRUE,
  summaryFunction=twoClassSummary
)

model <- train(FL,data=trainset,method='glmnet',
               metric = "ROC",
               tuneGrid = expand.grid(.alpha=c(0,1),.lambda=seq(0,0.05,by=0.01)),
               trControl=MyTrainControl)
model
plot(model, metric='ROC')

####
################################################
################################################
###Tree:
cvCtrl <- trainControl(method = "repeatedcv", repeats = 3,
                       summaryFunction = twoClassSummary,
                       classProbs = TRUE)
set.seed(1)
rpartTune <- train(Class ~ ., data = training, method = "rpart",
                   tuneLength = 30, #automaticaly tune for 30 combos
                   metric = "ROC",
                   trControl = cvCtrl)
plot(rpartTune, scales = list(x = list(log = 10)))
predict(rpartTune$finalModel, newdata, type = "class")
predict(rpartTune, newdata)

rpartProbs <- predict(rpartTune, testing, type = "prob")
 library(pROC)
partROC <- roc(testing$Class, rpartProbs[, "PS"], levels = rev(testProbs$Class))
plot(rpartROC, type = "S", print.thres = .5)






#1. Linear models:
##lm
lmfit <- train(Salary ~., data = train,
               method='lm',
               trControl = fitControl,
               preProc=c('scale', 'center'))
lmfit
lmfit.pred <- predict(lmfit, test)


##Ridge:
fitControl <- trainControl(method = "cv",
                           number = 10)
# Set seq of lambda to test
lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

ridge <- train(Salary~., data = train,
               method='ridge',
               trControl = fitControl,
               #                tuneGrid = lambdaGrid
               preProcess=c('center', 'scale')
)

ridge

ridge.pred <- predict(ridge, test)

################################################
################################################
##svm

svmTune <- train(x = trainX,
                 y = training$Class,
                 method = "svmRadial",
                 # The default grid of cost parameters go from 2^-2,
                 # 0.5 to 1,
                 # Well fit 9 values in that sequence via the tuneLength
                 # argument.
                 tuneLength = 9,
                 ## Also add options from preProcess here too
                 preProc = c("center", "scale"),
                 metric = "ROC",
                 trControl = cvCtrl)
svmTune$finalModel
SVM Accuracy Profile
plot(svmTune, metric = "ROC", scales = list(x = list(log =
                                                       2)))
svmPred <- predict(svmTune, testing[, names(testing) != "Class"])
confusionMatrix(svmPred, testing$Class)

#xgboost
#random forest

###
################################################
################################################
###Model Comparison
cvValues <- resamples(list(CART = rpartTune, SVM = svmTune, C5.0 = c5Tune))
summary(cvValues)
xyplot(cvValues, metric = "ROC")
dotplot(cvValues, metric = "ROC")
